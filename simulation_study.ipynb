{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6fb2408-f460-4e73-b716-2f1a4179b38b",
   "metadata": {},
   "source": [
    "# Project- Winter Semester 2021-2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07805d8-6f27-44ec-8c44-76316f394bde",
   "metadata": {},
   "source": [
    "## Programming for Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a05adb2-fbcf-4e43-9889-486bfdb1ee1f",
   "metadata": {},
   "source": [
    "### Paul Mc Grath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10baa63-fa6d-4d23-8ebb-a44d05564f99",
   "metadata": {},
   "source": [
    "### Problem statement\n",
    "For this project you must create a data set by simulating a real-world phenomenon of your choosing. You may pick any phenomenon you wish <br> – you might pick one that is\n",
    "of interest to you in your personal or professional life. <br>Then, rather than collect data\n",
    "related to the phenomenon, you should model and synthesise such data using Python.<br><br>\n",
    "We suggest you use the numpy.random package for this purpose. <br>\n",
    "Specifically, in this project you should:\n",
    "- Choose a real-world phenomenon that can be measured and for which you could collect at least one-hundred data points across at least four different variables.\n",
    "- Investigate the types of variables involved, their likely distributions, and their relationships with each other.\n",
    "- Synthesise/simulate a data set as closely matching their properties as possible.\n",
    "- Detail your research and implement the simulation in a Jupyter notebook – the data set itself can simply be displayed in an output cell within the notebook.\n",
    "Note that this project is about simulation – you must synthesise a data set. <br> <br>Some students may already have some real-world data sets in their own files. It is okay tobase your synthesised data set on these should you wish (please reference it if you do),<br>\n",
    "but the main task in this project is to create a synthesised data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709a2f71-a7ea-4c75-b5af-a699a4fc1284",
   "metadata": {},
   "source": [
    "Lecturer example:\n",
    "\n",
    "### Title: Performance of students studying a 10 credit module\n",
    "\n",
    "Most interesting variable:\n",
    "- Mark a student receives in the module **(grade)**\n",
    "\n",
    "**1 Find a real-world phenomenon as above.**\n",
    "\n",
    "**2 Investigate the problem (online)**\n",
    "\n",
    "Upon investigation of the problem:\n",
    "\n",
    "- number of hours a student studies per week **(hours)**\n",
    "- number of times the logon to Moodle in the first 3 weeks of term **(logins)**\n",
    "- previous level of degree qualification **(qual)**\n",
    "\n",
    "are closely related to (grade)\n",
    "\n",
    "*Hours and grade* variables will be *non-negative, read numbers* with *two decimal places*\n",
    "*Logins* will be a *non-zero integer* and *qual* will be a *categorical variable* with four possible values: *none, bachelors, masters or PhD*\n",
    "\n",
    "\n",
    "**3.  I investigate the other '4' variables, and I also look at the  relationship between the variables: **\n",
    "\n",
    "**3a investigate the other '4' variables**\n",
    "\n",
    "- how many students do well when it cones to grades\n",
    "- how many students don't do well\n",
    "- is the average grade 50-60% for example (this would establish the mean)\n",
    "- whats the standard deviation\n",
    "\n",
    "- Hours per week\n",
    "After some online research I find that full-time postgraduate students study on average *4 hours per week* with a standard deviation of *1/4 hour* and that a *normal distribution* is an acceptable model of such a variable.\n",
    "\n",
    "- Logins per week\n",
    "\n",
    "- Qualification\n",
    "\n",
    "- Grade\n",
    "\n",
    "**3b explore the relationship between the variables** e.g \n",
    "\n",
    "- logins vs grade (positive linear correlation?scatter plot)\n",
    "- hours vs grade (positive linear correlation? scatter plot)\n",
    "- qual vs grade (correlation? bar histogram/scatter plot)\n",
    "\n",
    " after detailed research I establish that it may be able to predict students grades based on the data that was available based on looking at the above features\n",
    "\n",
    "**devise an algorithm (or method)  to generate such a dataset**\n",
    "\n",
    " e.g. simulating values of the 4 variables for two hunderd students\n",
    " \n",
    "**Detail all the work in a notebook and then add some code to generate a dataset with those properties**\n",
    " \n",
    " - all of these are design choices made by the data analyst\n",
    " - can try to find relationship of peoples grades to number of hours studied per week, or hpw grafes can relate to consistent engagement through the semester\n",
    " \n",
    " -at the end of the day the code is going to be quite small in the notebook e.g.\n",
    " \n",
    " - identify variable w (i.e. grade)\n",
    " - identify distribution it should follow i.e normal/binomial/poisson\n",
    " - estimate the standard deviation from online research\n",
    " - generate an array of 200 data points using numpy.random algorithm\n",
    " - repeat for variables x, y and z.  (HOW THEY LINK TO EACH OTHER)\n",
    " - construct pandas dataframe with 200 data points for variables w,x,y and z\n",
    " - plot relationship (scatteer plot, matplotlib)\n",
    " - summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40202c62-5e1b-4b1a-a682-3f2f89635d73",
   "metadata": {},
   "source": [
    "### Prescribed reading\n",
    "\n",
    "https://realpython.com/simpy-simulating-with-python/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c945b684-db74-4b28-b89a-57d58a242f15",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=KAmZe5D3v5I\n",
    "\n",
    "In this in-depth Python tutorial using NumPy and Matplotlib, Caelan walks you through how to simulate the spread of a virus, using covid-19 as an example. We hope in watching this tutorial that you learn something about programming and pandemics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ba427c-4bf7-43e3-b812-f5e4107a70fb",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/monte-carlo-simulation-and-variants-with-python-43e3e7c59e1f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272d3792-b613-42f1-9a2c-902a31b1b0c2",
   "metadata": {},
   "source": [
    "Below code excerpts from https://livebook.manning.com/book/data-science-bookcamp/chapter-3/v-4/55"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351dc4a3-7e39-4493-944c-fde2fbac377c",
   "metadata": {},
   "source": [
    "NumPy, which stands for Numerical Python, is the engine that powers Pythonic data science. Python, despite its many virtues, is simply not suited for large-scale numeric analysis. Hence, data scientists must rely on the external NumPy library to efficiently manipulate and store numeric data. NumPy is an incredibly powerful tool for processing large collections of raw numbers. Thus, many of Python’s external data-processing libraries are NumPy-compatible. One such library is Matplotlib, which we introduced in the previous section. Other NumPy-driven libraries will be discussed in later portions of the book. This section focuses on randomized numerical simulations. We will leverage NumPy to analyze billions of random data-points. These random observations will allow us to learn hidden probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e315883-965a-4641-8c55-21c6335420de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb860356-8cf2-4362-9010-4ed68ad8c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_roll = np.random.randint(1, 7)\n",
    "assert 1 <= dice_roll <= 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad1861d-f807-42ff-916c-31aaef98eff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seeding reproducible random dice-rolls\n",
    "np.random.seed(0)\n",
    "dice_rolls = [np.random.randint(1, 7) for _ in range(3)]\n",
    "assert dice_rolls == [5, 6, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50edd8cd-546a-4417-99b4-939c988152aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating one fair coin-flip\n",
    "\n",
    "np.random.seed(0)\n",
    "coin_flip = np.random.randint(0, 2)\n",
    "print(f\"Coin landed on {'heads' if coin_flip == 1 else 'tails'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0739e972-92b1-4d2d-b889-0ae1e9d95145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating 10 fair coin-flips\n",
    "\n",
    "np.random.seed(0)\n",
    "def frequency_heads(coin_flip_sequence):\n",
    "    total_heads = sum(coin_flip_sequence)\n",
    "    return total_heads / len(coin_flip_sequence)\n",
    "\n",
    "coin_flips = [np.random.randint(0, 2) for _ in range(10)]\n",
    "freq_heads = frequency_heads(coin_flips)\n",
    "print(f\"Frequency of Heads is {freq_heads}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0455c860-d448-4c2c-a5cd-c5d5ba025422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting simulated fair coin-flip frequencies\n",
    "\n",
    "np.random.seed(0)\n",
    "coin_flips = []\n",
    "frequencies = []\n",
    "for _ in range(1000):\n",
    "    coin_flips.append(np.random.randint(0, 2))\n",
    "    frequencies.append(frequency_heads(coin_flips))\n",
    "\n",
    "plt.plot(list(range(1000)), frequencies)\n",
    "plt.axhline(.5, color='k')\n",
    "plt.xlabel('Number of Coin Flips')\n",
    "plt.ylabel('Head-Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98a444d-c022-451c-80d8-cd9a554b779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating biased coin-flips\n",
    "\n",
    "np.random.seed(0)\n",
    "print(\"Lets flip the biased coin once.\")\n",
    "coin_flip = np.random.binomial(1, .7)\n",
    "print(f\"Biased coin landed on {'heads' if coin_flip == 1 else 'tails'}.\")\n",
    "\n",
    "print(\"\\nLets flip the biased coin 10 times.\")\n",
    "number_coin_flips = 10\n",
    "head_count = np.random.binomial(number_coin_flips, .7)\n",
    "print((f\"{head_count} heads were observed out of \"\n",
    "       f\"{number_coin_flips} biased coin flips\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878a23a9-9d45-4eef-b2ea-09be5c3de1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing coin-flip frequency convergence\n",
    "\n",
    "np.random.seed(0)\n",
    "head_count = np.random.binomial(1000, .7)\n",
    "frequency = head_count / 1000\n",
    "print(f\"Frequency of Heads is {frequency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eed693-647a-4d9d-9df7-d9e2216991b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-computing coin-flip frequency convergence\n",
    "\n",
    "np.random.seed(0)\n",
    "assert np.random.binomial(1000, .7) / 1000 == 0.697\n",
    "for i in range(1, 6):\n",
    "    head_count = np.random.binomial(1000, .7)\n",
    "    frequency = head_count / 1000\n",
    "    print(f\"Frequency at iteration {i} is {frequency}\")\n",
    "    if frequency == 0.7:\n",
    "        print(\"Frequency equals the probability!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437f63e2-36f8-415f-8175-97aadd0d9673",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4421a963-bca2-4dea-9eb5-68f448bfde7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.binomial(1, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9460eca9-a719-441c-b9d2-6aa03e7e3f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.binomial(x, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff60b05-3dd8-4bfb-a657-85934fa3eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.binomial(x, p, size=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644ce1b4-2d38-4866-84ea-7d3b29069ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(frequency_array, bins='auto', edgecolor='black')\n",
    "plt.xlabel('Binned Frequency')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c14621-7ea9-4632-86fd-24ea5ff923c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram’s relative likelihoods\n",
    "likelihoods, bin_edges, _ = plt.hist(frequency_array, bins='auto', edgecolor='black', density=True)\n",
    "plt.xlabel('Binned Frequency')\n",
    "plt.ylabel('Relative Likelihood')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8b970d-bea4-4942-beb5-def6697f86c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coloring histogram bars over an interval\n",
    "\n",
    "likelihoods, bin_edges, patches = plt.hist(frequency_array, bins='auto',\n",
    "                                           edgecolor='black', density=True)\n",
    "bin_width = bin_edges[1] - bin_edges[0]\n",
    "start_index, end_index = compute_high_confidence_interval(likelihoods,\n",
    "                                                          bin_width)\n",
    "\n",
    "for i in range(start_index, end_index):\n",
    "     patches[i].set_facecolor('yellow')\n",
    "plt.xlabel('Binned Frequency')\n",
    "plt.ylabel('Relative Likelihood')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b87433c-d71c-4292-8895-3927961bf61b",
   "metadata": {},
   "source": [
    "### USEFUL HISTOGRAM FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1b3dfa-0903-488c-90ea-8f3d5c0e95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data, num_bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0357d49c-b4e5-4fdc-9f74-c58bfe43bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data, num_bins=auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9e8d8b-103d-4b54-a2cf-a6046df1c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data, edges=black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d965e5c1-bce9-4dee-92b7-2451e541d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, _, _ = plt.hist(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd26d5bb-afa9-41f8-901b-3b1fb70974db",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, bin_edges, _ = plt.hist(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa86f82-160e-46ef-a810-929ff72025ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihoods, _, _ = plt.hist(data, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5655c05-6cee-43a1-91ee-4e801dbf0252",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, patches = plt.hist(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d952a8-05cc-41b7-8111-29fa7a8a83e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihoods, bin_edges = np.histogram(data, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0515b8-14aa-4fab-90b4-4d8cca50d71d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99824745-72e8-4729-a5b6-097c114af4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "print(\"Lets flip the biased coin once.\")\n",
    "coin_flip = np.random.binomial(1, .7)\n",
    "print(f\"Biased coin landed on {'heads' if coin_flip == 1 else 'tails'}.\")\n",
    "\n",
    "print(\"\\nLets flip the biased coin 10 times.\")\n",
    "number_coin_flips = 10\n",
    "head_count = np.random.binomial(number_coin_flips, .7)\n",
    "print((f\"{head_count} heads were observed out of \"\n",
    "       f\"{number_coin_flips} biased coin flips\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fa976b-869f-4670-a8a0-03729c5fafea",
   "metadata": {},
   "source": [
    "### Summary\n",
    "The np.random.binomial method can simulate random coin-flips. The method gets its name from the Binomial distribution, which is a generic distribution that captures coin-flip probabilities.\n",
    "When a coin is flipped repeatedly, its frequency of heads converges towards the actual probability of heads. However, the final frequency might differ slightly from the actual probability.\n",
    "We can visualize the variability of recorded coin-flip frequencies by plotting a histogram. A histogram shows binned counts of observed numeric values. The counts can be transformed into relative likelihoods, so that the area beneath the histogram sums to 1. Effectively, the transformed histogram becomes a probability distribution. The area around the distribution’s peak represents a confidence interval. A confidence interval is the likelihood that an unknown probability falls within a certain frequency range. Generally, we prefer a confidence interval that is at 95% or higher.\n",
    "The shape of a frequency histogram will resemble a bell-shaped curve when the number of sampled frequencies is high. This curve is commonly referred to as the Bell curve, or the Normal distribution. According to the Central Limit Theorem, the 95% confidence interval associated with the Bell curve will grow more narrow as the size of each frequency sample goes up.\n",
    "Simulated card shuffles can be carried out using the np.random.permutation method. The method returns a random permutation of the inputted deck of cards. The permutation represents a random ordering of card elements. We can iterate over every possible permutation by calling itertools.permutations. Iterating over all the permutations for a 52 card deck is computationally impossible. However, we can easily capture all the permutations of a smaller 10-card deck. These permutations can be used to compute the small deck’s sample space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38a7818-c4f5-442b-b9be-2c6ca1ea3c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cd73bb-c883-4c18-83ed-08f94c435e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
